<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FK Conversational AI</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #0f0f0f 0%, #1a1a1a 100%);
            color: #ffffff;
            height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            overflow: hidden;
        }

        .container {
            text-align: center;
            padding: 2rem;
            max-width: 600px;
            width: 100%;
        }

        h1 {
            font-size: 2.5rem;
            font-weight: 300;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .subtitle {
            color: #888;
            font-size: 1rem;
            margin-bottom: 3rem;
        }

        .mic-container {
            position: relative;
            width: 200px;
            height: 200px;
            margin: 0 auto 2rem;
        }

        .conversation-indicator {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            border: 3px solid #333;
            background: #1a1a1a;
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            overflow: hidden;
        }

        .conversation-indicator.connected {
            border-color: #667eea;
            box-shadow: 0 0 30px rgba(102, 126, 234, 0.3);
        }

        .conversation-indicator.listening {
            animation: pulse-listening 2s infinite;
            border-color: #38ef7d;
        }

        .conversation-indicator.speaking {
            animation: pulse-speaking 1s infinite;
            border-color: #f5576c;
        }

        @keyframes pulse-listening {
            0% {
                box-shadow: 0 0 30px rgba(56, 239, 125, 0.3);
            }
            50% {
                box-shadow: 0 0 50px rgba(56, 239, 125, 0.6);
            }
            100% {
                box-shadow: 0 0 30px rgba(56, 239, 125, 0.3);
            }
        }

        @keyframes pulse-speaking {
            0% {
                box-shadow: 0 0 30px rgba(245, 87, 108, 0.3);
            }
            50% {
                box-shadow: 0 0 50px rgba(245, 87, 108, 0.6);
            }
            100% {
                box-shadow: 0 0 30px rgba(245, 87, 108, 0.3);
            }
        }

        .waveform {
            display: flex;
            align-items: center;
            gap: 3px;
            height: 60px;
        }

        .waveform-bar {
            width: 4px;
            background: #667eea;
            border-radius: 2px;
            transition: height 0.1s ease;
            opacity: 0.8;
        }

        .conversation-indicator.listening .waveform-bar {
            background: #38ef7d;
            animation: wave 1.2s ease-in-out infinite;
        }

        .conversation-indicator.speaking .waveform-bar {
            background: #f5576c;
            animation: wave 0.8s ease-in-out infinite;
        }

        .waveform-bar:nth-child(1) { animation-delay: 0s; }
        .waveform-bar:nth-child(2) { animation-delay: 0.1s; }
        .waveform-bar:nth-child(3) { animation-delay: 0.2s; }
        .waveform-bar:nth-child(4) { animation-delay: 0.3s; }
        .waveform-bar:nth-child(5) { animation-delay: 0.4s; }
        .waveform-bar:nth-child(6) { animation-delay: 0.5s; }
        .waveform-bar:nth-child(7) { animation-delay: 0.6s; }
        .waveform-bar:nth-child(8) { animation-delay: 0.7s; }

        @keyframes wave {
            0%, 100% { height: 20px; }
            50% { height: 40px; }
        }

        .status {
            font-size: 1.1rem;
            margin-bottom: 1rem;
            height: 30px;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 0.5rem;
        }

        .status-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #888;
            transition: background 0.3s ease;
        }

        .status.connected .status-dot {
            background: #38ef7d;
            animation: blink 2s infinite;
        }

        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .controls {
            display: flex;
            gap: 1rem;
            justify-content: center;
            margin-top: 2rem;
        }

        .control-button {
            padding: 0.75rem 1.5rem;
            border: 1px solid #333;
            background: transparent;
            color: #888;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 0.9rem;
        }

        .control-button:hover {
            border-color: #667eea;
            color: #667eea;
            background: rgba(102, 126, 234, 0.1);
        }

        .control-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .control-button.active {
            background: rgba(102, 126, 234, 0.2);
            border-color: #667eea;
            color: #667eea;
        }

        .transcript {
            margin-top: 2rem;
            padding: 1rem;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            max-height: 200px;
            overflow-y: auto;
            text-align: left;
            display: none;
        }

        .transcript.show {
            display: block;
        }

        .transcript-item {
            margin-bottom: 0.5rem;
            padding: 0.5rem;
            border-radius: 6px;
        }

        .transcript-item.user {
            background: rgba(102, 126, 234, 0.2);
            margin-left: 20%;
        }

        .transcript-item.agent {
            background: rgba(56, 239, 125, 0.2);
            margin-right: 20%;
        }

        .error {
            color: #f5576c;
            margin-top: 1rem;
            font-size: 0.9rem;
        }

        .mic-icon {
            width: 48px;
            height: 48px;
            color: #667eea;
            display: none;
        }

        .conversation-indicator:not(.connected) .mic-icon {
            display: block;
        }

        .conversation-indicator:not(.connected) .waveform {
            display: none;
        }

        @media (max-width: 600px) {
            h1 { font-size: 2rem; }
            .mic-container { 
                width: 150px;
                height: 150px;
            }
            .conversation-indicator {
                width: 120px;
                height: 120px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>FK Conversational AI</h1>
        <p class="subtitle">AI Voice Assistant</p>
        
        <div class="mic-container">
            <div id="conversationIndicator" class="conversation-indicator">
                <svg class="mic-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
                    <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
                    <line x1="12" y1="19" x2="12" y2="23"></line>
                    <line x1="8" y1="23" x2="16" y2="23"></line>
                </svg>
                <div class="waveform">
                    <div class="waveform-bar" style="height: 20px;"></div>
                    <div class="waveform-bar" style="height: 30px;"></div>
                    <div class="waveform-bar" style="height: 25px;"></div>
                    <div class="waveform-bar" style="height: 35px;"></div>
                    <div class="waveform-bar" style="height: 35px;"></div>
                    <div class="waveform-bar" style="height: 25px;"></div>
                    <div class="waveform-bar" style="height: 30px;"></div>
                    <div class="waveform-bar" style="height: 20px;"></div>
                </div>
            </div>
        </div>
        
        <div class="status" id="status">
            <span class="status-dot"></span>
            <span id="statusText">Loading SDK...</span>
        </div>
        
        <div class="error" id="error"></div>
        
        <div class="controls">
            <button id="connectBtn" class="control-button" disabled>Connect</button>
            <button id="muteBtn" class="control-button" disabled>Mute</button>
            <button id="transcriptBtn" class="control-button">Show Transcript</button>
        </div>
        
        <div class="transcript" id="transcript"></div>
    </div>

    <!-- Load LiveKit SDK from CDN -->
    <script src="https://cdn.jsdelivr.net/npm/livekit-client@2.5.7/dist/livekit-client.umd.min.js"></script>
    
    <script>
        // Configuration
        const LIVEKIT_URL = 'wss://fk-ivr-utmji7un.livekit.cloud';
        const TOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3NTEzNzEzMDEsImlzcyI6IkFQSUR6N1luYjJSdXRBSiIsIm5iZiI6MTc1MTI4NDkwMSwic3ViIjoidXNlci0xMjMiLCJ2aWRlbyI6eyJjYW5QdWJsaXNoIjp0cnVlLCJjYW5QdWJsaXNoRGF0YSI6dHJ1ZSwiY2FuU3Vic2NyaWJlIjp0cnVlLCJyb29tIjoiY29udmVyc2lmeS1kZXYiLCJyb29tSm9pbiI6dHJ1ZX19.Ym9veUiRuTMNy7KueF-M931PLcvPHxHg8c6oFgQLNJA';

        // Global variables
        let room;
        let audioTrack;
        let isConnected = false;
        let isMuted = false; // Start unmuted for natural conversation
        let LiveKitSDK;
        let agentSpeaking = false;
        let userSpeaking = false;

        // Get DOM elements
        const conversationIndicator = document.getElementById('conversationIndicator');
        const statusText = document.getElementById('statusText');
        const status = document.getElementById('status');
        const error = document.getElementById('error');
        const connectBtn = document.getElementById('connectBtn');
        const muteBtn = document.getElementById('muteBtn');
        const transcriptBtn = document.getElementById('transcriptBtn');
        const transcript = document.getElementById('transcript');

        // Wait for SDK to load
        function waitForLiveKit() {
            return new Promise((resolve) => {
                const checkInterval = setInterval(() => {
                    if (typeof LivekitClient !== 'undefined') {
                        LiveKitSDK = LivekitClient;
                        clearInterval(checkInterval);
                        resolve();
                    } else if (typeof LiveKit !== 'undefined') {
                        LiveKitSDK = LiveKit;
                        clearInterval(checkInterval);
                        resolve();
                    } else if (typeof window.LivekitClient !== 'undefined') {
                        LiveKitSDK = window.LivekitClient;
                        clearInterval(checkInterval);
                        resolve();
                    } else if (typeof window.LiveKit !== 'undefined') {
                        LiveKitSDK = window.LiveKit;
                        clearInterval(checkInterval);
                        resolve();
                    }
                }, 100);

                setTimeout(() => {
                    clearInterval(checkInterval);
                    resolve();
                }, 10000);
            });
        }

        // Initialize app when SDK is ready
        async function initializeApp() {
            await waitForLiveKit();

            if (!LiveKitSDK) {
                error.textContent = 'LiveKit SDK failed to load. Please refresh the page.';
                statusText.textContent = 'SDK Error';
                console.error('LiveKit SDK not found after waiting');
                return;
            }

            console.log('LiveKit SDK loaded successfully:', LiveKitSDK);
            statusText.textContent = 'Ready to connect';
            connectBtn.disabled = false;
        }

        // Update UI based on conversation state
        function updateConversationState() {
            conversationIndicator.classList.remove('listening', 'speaking');
            
            if (!isConnected) {
                statusText.textContent = 'Disconnected';
                return;
            }

            if (agentSpeaking) {
                conversationIndicator.classList.add('speaking');
                statusText.textContent = 'Assistant is speaking...';
            } else if (userSpeaking) {
                conversationIndicator.classList.add('listening');
                statusText.textContent = 'Listening to you...';
            } else {
                statusText.textContent = 'Ready - Just speak!';
            }
        }

        // Voice Activity Detection for visual feedback
        function setupVoiceActivityDetection(audioTrack) {
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;
            const dataArray = new Uint8Array(analyser.frequencyBinCount);

            // Get the media stream from the audio track
            const mediaStream = new MediaStream([audioTrack.mediaStreamTrack]);
            const source = audioContext.createMediaStreamSource(mediaStream);
            source.connect(analyser);

            function checkAudioLevel() {
                analyser.getByteFrequencyData(dataArray);
                const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
                
                // Simple threshold-based detection
                const wasUserSpeaking = userSpeaking;
                userSpeaking = average > 30 && !isMuted; // Adjust threshold as needed
                
                if (wasUserSpeaking !== userSpeaking) {
                    updateConversationState();
                }

                if (isConnected) {
                    requestAnimationFrame(checkAudioLevel);
                }
            }

            checkAudioLevel();
        }

        // Connect to LiveKit room
        async function connectToRoom() {
            try {
                error.textContent = '';
                statusText.textContent = 'Connecting...';
                connectBtn.disabled = true;

                console.log('Creating Room object with SDK:', LiveKitSDK);
                
                room = new LiveKitSDK.Room({
                    adaptiveStream: true,
                    dynacast: true,
                    autoSubscribe: true,
                });

                // Set up event handlers
                room.on('connected', () => {
                    console.log('Connected to room');
                    isConnected = true;
                    status.classList.add('connected');
                    conversationIndicator.classList.add('connected');
                    muteBtn.disabled = false;
                    connectBtn.textContent = 'Disconnect';
                    connectBtn.disabled = false;
                    updateConversationState();
                });

                room.on('disconnected', (reason) => {
                    console.log('Disconnected from room:', reason);
                    handleDisconnect();
                });

                room.on('participantConnected', (participant) => {
                    console.log('Participant connected:', participant.identity);
                    if (participant.identity !== 'conversify-dev') {
                        addToTranscript(`${participant.identity} joined`, 'system');
                    }
                });

                room.on('trackSubscribed', (track, publication, participant) => {
                    console.log('Track subscribed:', track.kind, 'from', participant.identity);
                    if (track.kind === 'audio' && participant.identity !== 'conversify-dev') {
                        const audioElement = track.attach();
                        document.body.appendChild(audioElement);
                        
                        // Monitor agent's speaking state
                        audioElement.addEventListener('play', () => {
                            agentSpeaking = true;
                            updateConversationState();
                        });
                        
                        audioElement.addEventListener('pause', () => {
                            agentSpeaking = false;
                            updateConversationState();
                        });
                        
                        audioElement.addEventListener('ended', () => {
                            agentSpeaking = false;
                            updateConversationState();
                        });
                        
                        audioElement.play().catch(e => console.error('Audio play failed:', e));
                    }
                });

                room.on('trackUnsubscribed', (track, publication, participant) => {
                    if (track.kind === 'audio' && participant.identity !== 'conversify-dev') {
                        agentSpeaking = false;
                        updateConversationState();
                    }
                });

                room.on('error', (err) => {
                    console.error('Room error:', err);
                    error.textContent = `Room error: ${err.message}`;
                });

                // Connect to room
                console.log('Connecting to room...');
                await room.connect(LIVEKIT_URL, TOKEN);
                console.log('Successfully connected!');

                // Create and publish audio track - START UNMUTED for natural conversation
                console.log('Creating local audio track...');
                audioTrack = await LiveKitSDK.createLocalAudioTrack({
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                });

                await room.localParticipant.publishTrack(audioTrack);
                console.log('Audio track published - microphone is active!');
                
                // Set up voice activity detection
                setupVoiceActivityDetection(audioTrack);
                
                // The conversation is ready to start naturally
                addToTranscript('Connected! Just start speaking - I\'m listening.', 'system');

            } catch (err) {
                console.error('Connection failed:', err);
                error.textContent = `Connection failed: ${err.message}`;
                connectBtn.disabled = false;
                connectBtn.textContent = 'Connect';
                statusText.textContent = 'Connection failed';
            }
        }

        function handleDisconnect() {
            isConnected = false;
            agentSpeaking = false;
            userSpeaking = false;
            status.classList.remove('connected');
            conversationIndicator.classList.remove('connected', 'listening', 'speaking');
            muteBtn.disabled = true;
            muteBtn.classList.remove('active');
            connectBtn.textContent = 'Connect';
            connectBtn.disabled = false;
            isMuted = false;
            updateConversationState();
        }

        // Mute button handler
        muteBtn.addEventListener('click', async () => {
            if (!isConnected || !audioTrack) return;

            try {
                if (isMuted) {
                    await audioTrack.unmute();
                    muteBtn.textContent = 'Mute';
                    muteBtn.classList.remove('active');
                    isMuted = false;
                    console.log('Microphone unmuted');
                } else {
                    await audioTrack.mute();
                    muteBtn.textContent = 'Unmute';
                    muteBtn.classList.add('active');
                    isMuted = true;
                    userSpeaking = false;
                    console.log('Microphone muted');
                }
                updateConversationState();
            } catch (err) {
                console.error('Error toggling microphone:', err);
                error.textContent = `Microphone error: ${err.message}`;
            }
        });

        // Connect button handler
        connectBtn.addEventListener('click', async () => {
            if (isConnected && room) {
                await room.disconnect();
            } else {
                await connectToRoom();
            }
        });

        // Transcript toggle
        transcriptBtn.addEventListener('click', () => {
            transcript.classList.toggle('show');
            transcriptBtn.textContent = transcript.classList.contains('show') 
                ? 'Hide Transcript' 
                : 'Show Transcript';
        });

        // Add message to transcript
        function addToTranscript(text, speaker = 'user') {
            const item = document.createElement('div');
            item.className = `transcript-item ${speaker}`;
            if (speaker === 'system') {
                item.style.background = 'rgba(136, 136, 136, 0.2)';
                item.style.textAlign = 'center';
                item.style.margin = '0.5rem 0';
                item.textContent = text;
            } else {
                item.textContent = `${speaker === 'user' ? 'You' : 'Assistant'}: ${text}`;
            }
            transcript.appendChild(item);
            transcript.scrollTop = transcript.scrollHeight;
        }

        // Start initialization when page loads
        window.addEventListener('load', initializeApp);
    </script>
</body>
</html>