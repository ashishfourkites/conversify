# Conversify Configuration

# Logging Configuration
logging:
  level: DEBUG  # DEBUG, INFO, WARNING, ERROR
  file: app.log
  format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'

# LiveKit Configuration
livekit:
  auto_subscribe: SUBSCRIBE_ALL  # Options: SUBSCRIBE_ALL, NONE
  room:
    name: conversify-room

# Worker Configuration
worker:
  job_memory_warn_mb: 1900  # Memory usage warning threshold in MB
  load_threshold: 1  # CPU load threshold for worker
  job_memory_limit_mb: 10000  # Maximum memory limit in MB

# Voice Pipeline Configuration
pipeline:
  allow_interruptions: true
  interrupt_speech_duration: 0.5
  interrupt_min_words: 0
  min_endpointing_delay: 0.3
  preemptive_synthesis: true

# Voice Activity Detection
vad:
  model: silero
  min_speech_duration: 0.20
  min_silence_duration: 0.50
  prefix_padding_duration: 0.5
  max_buffered_speech: 60.0
  activation_threshold: 0.5
  force_cpu: false
  sample_rate: 16000

# End of Utterance Detection
eou:
  enabled: true
  model: turn_detector
  unlikely_threshold: 0.0289

# Speech-to-Text Configuration
stt:
  implementation: whisper
  whisper:
    model: "deepdml/faster-whisper-large-v3-turbo-ct2"
    device: cuda
    compute_type: float16
    language: en
    cache_dir: models
    model_cache_directory: "/Workspace/tr/repos/s2s/models"
    warmup_audio: "/Workspace/tr/repos/s2s/input/warmup_audio.wav"

# Language Model Configuration
llm:
  implementation: openai
  openai:
    model: "Qwen/Qwen2.5-VL-3B-Instruct-AWQ"
    temperature: 0.4
    parallel_tool_calls: false
    max_tokens: 1024
    api_url: "http://127.0.0.1"
    api_port: 30000
    api_path: "/v1"  

# Text-to-Speech Configuration
tts:
  implementation: kokoro
  kokoro:
    model: "tts-1"
    voice: af_heart
    speed: 1.0
    api_url: "http://0.0.0.0"
    api_port: 8880
    api_path: "/v1" 
  sample_rate: 24000
  channels: 1

# Video Processing
video:
  enabled: false
  process_interval_ms: 200  