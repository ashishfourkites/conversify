agent:
  env_file: ".env.local"
  instructions_file: conversify/prompts/llm.txt
  greeting: "Hey! How are you doing today?"
  goodbye: "Goodbye! Have a great day!"
  default_participant_identity: "identity-qfXx"
  use_eou: false                                      # livekit turn detection
  use_background_noise_removal: true                  # uses Krisp BVC noise cancellation
  use_background_audio: false                         # plays office background audio and keyboard typing sound while the agent speaks
  allow_interruptions: True                           # reset tts on user iterruption

stt:
  whisper:
    language: "en"
    model: "guillaumekln/faster-whisper-tiny"  # Pre-converted model
    device: "cpu"
    compute_type: "int8"
    model_cache_directory: "conversify/data/models_cache"
    warmup_audio: "conversify/data/warmup_audio.wav"

llm:
  api_key: "3d1704dc0fea4e0fae7f909d99f9ddaf"
  base_url: "https://phd-ai-poc.openai.azure.com/"
  azure_deployment: "gpt-4"
  api_version: "2024-02-01"
  model: "gpt-4"
  temperature: 0.4
  parallel_tool_calls: false
  tool_choice: "auto"

tts:
  kokoro:
    base_url: "http://0.0.0.0:8880/v1" 
    api_key: "NULL"                     
    model: "tts-1"                      
    voice: "af_heart"                   
    speed: 1.0     

vad:
  min_speech_duration: 0.20             # Minimum duration (seconds) for speech detection
  min_silence_duration: 0.40            # Minimum silence duration (seconds) to detect end of speech
  prefix_padding_duration: 0.5          # Padding duration (seconds) before detected speech
  max_buffered_speech: 60.0             # Maximum duration (seconds) of buffered speech
  activation_threshold: 0.5             # Threshold for voice activation detection
  force_cpu: false                      # Force VAD to run on CPU instead of GPU
  sample_rate: 16000  

vision:
  use: false                            
  video_frame_interval: 0.2   

memory:
  use: false                             
  dir: "conversify/data/memory_store"              
  load_last_n: 6       

embedding:
  vllm_model_name: "mixedbread-ai/mxbai-embed-large-v1"                             

worker:
  job_memory_warn_mb: 1900              
  load_threshold: 1.0                   
  job_memory_limit_mb: 10000            

logging:
  level: "DEBUG"                         
  file: "logs/app.log"                